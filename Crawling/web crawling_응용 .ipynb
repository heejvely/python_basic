{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee808c35",
   "metadata": {},
   "source": [
    "DOM(Document Object Model)의 정의\n",
    "- HTML, XML 문서의 프로그래밍 인터페이스 : 구조화된 표현 및 프로그래밍 언어가 DOM 구조에 접근할 수 있는 방법을 제공\n",
    "- 트리 구조로 형성되어 있음 : 부모 노드(위쪽), 자식 노드(아래쪽)\n",
    "- HTML에서 노드는 \\<head>, \\<body>, \\<h1>, \\<script> 등의 태그뿐만 아니라 태그 내 텍스트나 속성 모두 노드에 속함\n",
    "- BeautifulSoup 모듈의 함수를 활용하여 노드를 기준으로 원하는 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812f98d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<p align=\"center\" class=\"a\"> text1</p>\n",
      "\n",
      "\n",
      "<p align=\"center\" class=\"b\"> text2</p>\n",
      "\n",
      "\n",
      "<p align=\"center\" class=\"c\"> text3</p>\n",
      "\n",
      "\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html=\"\"\"\n",
    "<html>\n",
    "<head>\n",
    "    <title>crawler</title>\n",
    "</head>\n",
    "<body>\n",
    "    <p class=\"a\" align=\"center\"> text1</p>\n",
    "    <p class=\"b\" align=\"center\"> text2</p>\n",
    "    <p class=\"c\" align=\"center\"> text3</p>\n",
    "    <div>\n",
    "        <img src=\"/source\" width=\"300\" height=\"200\">\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "contents = bs.find('body')\n",
    "\n",
    "for child in contents.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661daae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<p align=\"center\" class=\"a\"> text1</p>\n",
      " text1\n",
      "\n",
      "\n",
      "<p align=\"center\" class=\"b\"> text2</p>\n",
      " text2\n",
      "\n",
      "\n",
      "<p align=\"center\" class=\"c\"> text3</p>\n",
      " text3\n",
      "\n",
      "\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n",
      "\n",
      "\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# body의 자손은 p, div, img\n",
    "for d in contents.descendants:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5900ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "img_tag = contents.find('img')\n",
    "print(img_tag)\n",
    "print(img_tag.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd904ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<p align=\"center\" class=\"a\"> text1</p>\n",
      "<p align=\"center\" class=\"b\"> text2</p>\n",
      "<p align=\"center\" class=\"c\"> text3</p>\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n",
      "</body> \n",
      "\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "contents = bs.find('body')\n",
    "print(img_tag.find_parent('body'),'\\n')\n",
    "print(img_tag.find_parent('div'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06330fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"center\" class=\"b\"> text2</p>\n"
     ]
    }
   ],
   "source": [
    "p_tag = bs.find('p',class_='b')\n",
    "print(p_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dfe2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a> \n",
      "\n",
      "<a class=\"link_newsstand\" data-clk=\"title\" href=\"http://newsstand.naver.com/\" target=\"_blank\">뉴스스탠드</a> \n",
      "\n",
      "<a class=\"link_newsstand\" data-clk=\"title\" href=\"http://newsstand.naver.com/\" target=\"_blank\">뉴스스탠드</a> \n",
      "\n",
      "뉴스스탠드\n",
      "구독한 언론사\n",
      "전체언론사\n"
     ]
    }
   ],
   "source": [
    "from urllib import request as req\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = req.urlopen('https://naver.com')\n",
    "bs = BeautifulSoup(res,'html.parser')\n",
    "print(bs.find('a'),'\\n')\n",
    "print(bs.find(class_='link_newsstand'),'\\n')\n",
    "print(bs.find('a',{'class':'link_newsstand'}),'\\n')\n",
    "\n",
    "# 클래스가 여러개인 경우\n",
    "eles = bs.find_all('a',{'class':['link_newsstand','btn_sort','btn_sort.sort_on']})\n",
    "for e in eles:\n",
    "    print(e.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817bc015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"logo_default\">\n",
      "<a class=\"logo_naver\" data-clk=\"top.logo\" href=\"/\"><span class=\"blind\">네이버</span></a>\n",
      "</h1> \n",
      "\n",
      "<h2 class=\"blind\">뉴스스탠드</h2> \n",
      "\n",
      "<h2 class=\"blind\">주제별 캐스트</h2> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hlists = bs.findAll({'h1','h2','h3','h4','h5','h6'},limit = 3)\n",
    "for h in hlists:\n",
    "    print(h,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da4ed6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/gifts/img1.jpg\n",
      "../img/gifts/img2.jpg\n",
      "../img/gifts/img3.jpg\n",
      "../img/gifts/img4.jpg\n",
      "../img/gifts/img6.jpg\n"
     ]
    }
   ],
   "source": [
    "# 정규표현식과 bs4\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "images = bs.find_all('img',{'src':re.compile('\\.\\.\\/img\\/gifts/img.*\\.jpg')})\n",
    "for image in images:\n",
    "    print(image['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한빛 네트워크 사이트 로그인 후 점수 가져오기\n",
    "\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome('C:/tool/chromedriver.exe')\n",
    "driver.get('https://www.hanbit.co.kr/')\n",
    "element = driver.find_element_by_class_name('login')\n",
    "element.click()\n",
    "m_id = ''\n",
    "m_passwd = ''\n",
    "\n",
    "element = driver.find_element_by_id('m_id')\n",
    "element.send_keys(m_id)\n",
    "time.sleep(1)\n",
    "\n",
    "element = driver.find_element_by_id('m_passwd')\n",
    "element.send_keys(m_passwd)\n",
    "time.sleep(1)\n",
    "\n",
    "element = driver.find_element_by_class_name('btn_login')\n",
    "element.click()\n",
    "\n",
    "driver.get('https://www.hanbit.co.kr/myhanbit/myhanbit.html')\n",
    "source = driver.page_source\n",
    "bs = BeautifulSoup(source, 'html.parser')\n",
    "a = bs.select_one('#container > div > div.sm_mymileage > dl.mileage_section1 > dd > span')\n",
    "print(a.text,'점')\n",
    "time.sleep(3)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93070ba3",
   "metadata": {},
   "source": [
    "header 확인: http://www.useragentstring.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b793933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Venom: Let There Be Carnage\n",
      "No Time To Die\n",
      "Free Guy\n",
      "Ice Age 5-Movie Collection\n",
      "Illumination Presents: Dr. Seuss' The Grinch\n",
      "The Hating Game\n",
      "Spider-Man: Far from Home\n",
      "Dr. Seuss' How the Grinch Stole Christmas\n",
      "Dune\n",
      "Shang-Chi and the Legend of the Ten Rings\n",
      "Yellowstone\n",
      "It's Always Sunny in Philadelphia\n",
      "Rick and Morty (Uncensored)\n",
      "Doctor Who\n",
      "South Park\n",
      "The Office\n",
      "Game of Thrones\n",
      "Naruto Shippuden Uncut\n",
      "The Flash\n",
      "The Big Bang Theory\n",
      "Keep the Wolves Close\n",
      "Winning Or Learning\n",
      "Phantom Pain\n",
      "Everybody Pays on the New Season of Yellowstone\n",
      "Yellowstone - A Long Line of Enemies\n",
      "1883: Two Journeys Extended Teaser\n",
      "Compliments of Captain Lee's Travel Agency\n",
      "2020: A Year In Review\n",
      "The Gang Buys a Roller Rink\n",
      "The Gang Replaces Dee with a Monkey\n"
     ]
    }
   ],
   "source": [
    "# 구글 플레이에서 인기 영화 제목 30개 출력(requests + bs4)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'}\n",
    "\n",
    "url = 'https://play.google.com/store/movies/top'\n",
    "\n",
    "res = requests.get(url)\n",
    "bs = BeautifulSoup(res.text,'html.parser')\n",
    "movies = bs.find_all('div',class_='WsMG1c nnK0zc')\n",
    "\n",
    "print(len(movies))\n",
    "for m in movies:\n",
    "    print(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1c2e666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크롤 완료\n",
      "132\n",
      "킬링 카인드: 킬러의 수제자\n",
      "노 서든 무브\n",
      "푸른 호수\n",
      "나인 데이즈 Nine Days\n",
      "베네데타\n",
      "스노우 몬스터\n",
      "빌리 홀리데이\n",
      "산타킬러스\n",
      "커밍 홈 인 더 다크\n",
      "퍼스트 카우\n",
      "뉴 오더\n",
      "메이드 인 이태리\n",
      "왼팔의 복서 닉\n",
      "스카이파이어\n",
      "파우더 블루\n",
      "8비트 크리스마스\n",
      "워빌로우\n",
      "사랑을 위하여\n",
      "언힐러\n",
      "더 매치: 1944\n",
      "나쁜 녀석들 : 포에버 Bad Boys for Life\n",
      "듄\n",
      "007 노 타임 투 다이\n",
      "크라이 마초\n",
      "스피릿\n",
      "미첼 가족과 기계 전쟁 Mitchells vs. the Machines, The\n",
      "푸른 호수\n",
      "H2: 어느 살인마의 가족 이야기\n",
      "랑종\n",
      "데쓰 프루프\n",
      "더 로스트 레오나르도Lost Leonardo, The\n",
      "팬보이즈\n",
      "땅속에\n",
      "슈퍼 히어로\n",
      "커밍 홈 인 더 다크\n",
      "에이펙스\n",
      "닌자거북이 (2007)\n",
      "플랜 A\n",
      "퍼스트 카우\n",
      "더 프레지던트\n",
      "퍼피 구조대 더 무비\n",
      "슈퍼 소닉\n",
      "범블비  (자막판)\n",
      "닌자 터틀\n",
      "줄무늬 파자마를 입은 소년\n",
      "보글보글 스폰지 밥\n",
      "엘라 인챈티드\n",
      "인생은 아름다워\n",
      "휴고\n",
      "스타더스트\n",
      "닌자터틀: 어둠의 히어로\n",
      "스파이 키드\n",
      "샬롯의 거미줄\n",
      "저지 걸\n",
      "천국의 아이들\n",
      "태양의 서커스 : 신비의 세계\n",
      "베놈 2: 렛 데어 비 카니지 Venom: Let There Be Carnage\n",
      "Free Guy\n",
      "정글 크루즈\n",
      "말리그넌트\n",
      "리스펙트\n",
      "이스케이프 룸 2: 노 웨이 아웃\n",
      "듄\n",
      "007 노 타임 투 다이\n",
      "퍼피 구조대 더 무비\n",
      "크라이 마초\n",
      "코다\n",
      "건파우더 밀크셰이크\n",
      "졸라 Zola\n",
      "시그널 X: 영혼의 구역\n",
      "스피릿\n",
      "미첼 가족과 기계 전쟁 Mitchells vs. the Machines, The\n",
      "테이큰\n",
      "H2: 어느 살인마의 가족 이야기\n",
      "경고\n",
      "새벽의 황당한 저주\n",
      "해리포터 시리즈 완결 패키지\n",
      "반지의 제왕: 3 영화 컬렉션 확장판 (자막판)\n",
      "신비한 동물들과 그린델왈드의 범죄/ 신비한 동물 사전 영화 패키지 (자막판)\n",
      "킹스맨 무비 컬렉션\n",
      "트랜스포머 영화 5편 컬렉션\n",
      "스타워즈 완전정복 패키지 (자막판)\n",
      "MIB 맨 인 블랙 풀 패키지 (자막판)\n",
      "인디아나 존스: 모험 컬렉션\n",
      "드래곤 길들이기 3부작 (더빙판)\n",
      "엑스맨 무비 컬렉션\n",
      "도리 & 니모 패키지 (더빙판) (자막판)\n",
      "스타워즈 디지털 콜렉션\n",
      "50가지 그림자: 3 무비 콜렉션\n",
      "메이즈러너 트릴로지 (자막판)\n",
      "미션 임파서블 1-5 컬렉션 (자막판)\n",
      "샤잠!/아쿠아맨 2 영화 컬렉션 (자막판)\n",
      "슈퍼배드 & 미니언즈: 4편의 무비 컬렉션 (더빙판)\n",
      "배트맨 완결 패키지 (자막판)\n",
      "거미줄에 걸린 소녀 / 밀레니엄: 여자를 증오한 남자들 (자막판)\n",
      "컨저링 유니버스 영화 컬렉션 (자막판)\n",
      "퍼피 구조대 더 무비\n",
      "슈퍼 소닉\n",
      "범블비  (자막판)\n",
      "닌자 터틀\n",
      "줄무늬 파자마를 입은 소년\n",
      "보글보글 스폰지 밥\n",
      "엘라 인챈티드\n",
      "인생은 아름다워\n",
      "휴고\n",
      "스타더스트\n",
      "닌자터틀: 어둠의 히어로\n",
      "스파이 키드\n",
      "샬롯의 거미줄\n",
      "저지 걸\n",
      "천국의 아이들\n",
      "태양의 서커스 : 신비의 세계\n",
      "듄\n",
      "맨 인 더 다크 2 Don't Breathe 2\n",
      "더 수어사이드 스쿼드\n",
      "분노의 질주: 더 얼티메이트\n",
      "킬링 카인드: 킬러의 수제자\n",
      "콰이어트 플레이스 2\n",
      "캐시트럭\n",
      "노바디\n",
      "고질라 VS. 콩\n",
      "건파우더 밀크셰이크\n",
      "졸트\n",
      "쥬라기 헌트\n",
      "아이스로드\n",
      "테이큰\n",
      "스노우 몬스터\n",
      "다이버전트 시리즈: 얼리전트\n",
      "퍼펙트스틸\n",
      "람보 2\n",
      "에이펙스\n",
      "USS 인디애나폴리스\n"
     ]
    }
   ],
   "source": [
    "# Q. 구글 플레이에서 인기 영화 제목 200개 출력(selenium + bs4)\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome('C:/tool/chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "url = 'https://play.google.com/store/movies/top'\n",
    "driver.get(url)\n",
    "\n",
    "# 1080 위치로 스크롤 내리기\n",
    "# driver.execute_script('window.scrollTo(0,1080)') \n",
    "# 화면 가장 아래로 스크롤 내리기\n",
    "# driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "\n",
    "import time\n",
    "\n",
    "# 현재 문서 높이를 가져와서 저장\n",
    "prev_height = driver.execute_script('return document.body.scrollHeight')\n",
    "\n",
    "# 반복 수행\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "    # 페이지 로딩 대기\n",
    "    driver.implicitly_wait(10) # 브라우저에서 파싱되는 지연 시간 기다려줌\n",
    "    curr_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    if curr_height == prev_height:\n",
    "        break\n",
    "    prev_height = curr_height\n",
    "print('스크롤 완료')\n",
    "\n",
    "bs = BeautifulSoup(driver.page_source,'html.parser')\n",
    "movies = bs.find_all('div',attrs = {'class':'Epkrse '})\n",
    "\n",
    "print(len(movies))\n",
    "for m in movies:\n",
    "    print(m.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
